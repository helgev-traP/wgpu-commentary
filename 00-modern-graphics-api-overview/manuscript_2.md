# 現代グラフィックAPI概説

目次

- 各回のURL
- ...

- 今回の内容
  - GPUの動かし方
  - レンダリングの格段で行われていること、プログラマの仕事とGPUの仕事
  - グラフィックパイプラインのCPU側の操作

## GPUの動き方

### CPUとGPU

GPUは処理主体ではありません。GPU単体で処理はできず、必要なデータやリソース、コマンドをCPU側から送る必要があります。GPUが利用するデータやテクスチャ、シェーダーコード、パイプライン状態の設定などはすべて一度完全にグラフィックボードにアップロードされないといけません。

```callout
- CPU側
  CPU・メインメモリ
- GPU側
  GPU・VRAM
  GPU側をすべてまとめて一般にグラフィックボードと呼びます。($GPU \in グラボ$)
```

この2つはPCIeを通して接続されます。PCIeでのデータ交換はGPU<->VRAMでのデータ交換よりもずっと、レイテンシの面でもスループットの面でも遅く、パフォーマンスに気を付けないと往々にしてPCIeがボトルネックとなります。この事実は後々レンダリングのパフォーマンス改善の回で思い出していただきます。
(ちなみに、CPUオンボードグラフィックを使用してる場合はメインメモリの中からVRAMとしていくらかの領域を割り当ててGPUに使わせます)

### グラフィックAPI規格

GPUは処理主体ではないのでCPUからPCIeを通してコマンドを送り続けないといけません。これはGPUベンダー(NVIDIA, AMD, Intel)が提供するドライバーが行います。それらのドライバーを利用できるようにするためのAPIがグラフィックAPIです。
昔(数十年前？)はGPUベンダー各社が独自のAPI規格を公開していたそうです。しかしそれではGPUごとにプログラムを組み直さなければならないため、統一規格が提案され、現代でのGPUプログラミング環境となっています。

現在使われているグラフィックAPI規格で、直接GPUを操作している(つまりドライバーが直接APIを提供する形の)ものは以下の4つです。

- DirectX 12 / Direct3D 12
- Vulkan
- Metal
- OpenGL

これらの規格をサポートするドライバーをGPUベンダーからインストールすることで、GPUを操作できるようになります。
また、以上のAPIをラッピングしたAPI規格として以下のものもあります。

- WebGL
- WebGPU

このブログシリーズではWebGPUの実装であるwgpuを扱います。WebGPUとwgpuについては次回で詳しく説明します。
また、今後このシリーズ内で単にAPIと書いたときはグラフィックAPIのことを指します。

## 準備

### 座標変換について

GPUによるレンダリングを理解するためには同次座標の座標変換がやっていることを理解する必要があります。しかしそれはこのブログシリーズで扱いたい内容ではないため以下の記事に解説を譲ります。レンダリングパイプラインの章だけでもそれなりの理解は得られると思います。幸い、ほとんどの座標変換は専用の数学ライブラリを使えば中身の実装と数学を完全に理解せずとも使えます。←僕もこれです。

[３次元座標変換のメモ書き](https://zenn.dev/mebiusbox/articles/8e765148576919#%E3%83%A2%E3%83%87%E3%83%AB%E5%A4%89%E6%8F%9B%EF%BC%88modeling-transformation%EF%BC%89)

このへんのサイトもとても参考になるはずです。

[WebGL2入門 3D知識編](https://sbfl.net/blog/2016/09/05/webgl2-tutorial-3d-knowledge/)

### 正規化デバイス座標について

それと、正規化デバイス座標を説明しておく必要があります。正規化デバイス座標とは、レンダリングパスの描画範囲に相対的な座標系です。一般的なAPIでは、描画範囲の左下を{x=-1.0, y=-1.0}、右上を{x=1.0, y=1.0}とします。これに深度z軸に加えたものが正規化デバイス座標です。OpenGL系ではzの描画範囲は[-1.0, 1.0]、DirectX12, Vulkan, Metal, そしてWebGPUでは[0.0, 1.0]となります。

```callout
ちなみに、数学的にはOpenGL系の正規化デバイス座標の方が対称性があって自然で、他のAPIのことを変だと思っていた時期が僕にもありました。
しかし、z: [0.0, 1.0]の場合「Reversed-Zテクニック」というものが使えるようになり、深度テストの精度を上げることができるらしいです。詳しくは説明しません。
```

WebGPUでは正規化デバイス座標系でx: [-1.0, 1.0], y: [-1.0, 1.0], z: [0.0, 1.0]の範囲が描画範囲となります。

## モデルをレンダリングするまでに行われること　プログラマの仕事とGPUの仕事

### シェーダーがやること

CGレンダリングでのシェーダーは主に頂点シェーダーとフラグメントシェーダーの2つを使います。

```callout
ちなみにフラグメントシェーダーはピクセルシェーダーとも呼ばれますが、このシェーダーはピクセルごとに実行されるというよりはフラグメントごとに実行されます。フラグメントは各ピクセルごとに0を含む自然数個生成されるので、どちらかというとフラグメントシェーダーの方が実態に近い名前と言えるでしょう。
```

#### 頂点シェーダー | Vertex Shader

頂点シェーダーの仕事は、すべての頂点に対して最終的に表示されるべきスクリーン上の座標を計算することです。
表現したい世界の物理的な位置から、カメラの位置や向き、角度、焦点距離などを計算に入れて、最終的にすべての頂点について正規化デバイス座標系であるべき位置を計算します。

#### フラグメントシェーダー | Fragment Shader

頂点シェーダーで頂点位置が決定された後、GPUはすべてのポリゴンについて、そのポリゴンが内包するすべてのピクセルに対してフラグメントを生成します。これはGPU側で自動で行われます。
つまり、あるピクセルにどのポリゴンも重ならなかった場合、そのピクセルではフラグメントは生成されませんし、あるピクセルに複数のポリゴンが重なった場合、そのピクセルでは重なったポリゴンの数だけフラグメントが生成されます。
このフラグメントに対して、フラグメントシェーダーが実行されます。

#### 頂点シェーダーの出力とフラグメントシェーダーの入力

頂点シェーダーはユーザー定義データを出力し、フラグメントシェーダーに渡すことができます。
例えばそれは、頂点ごとの色やテクスチャ座標、法線ベクトルなどです。これらのデータはフラグメントの生成時に、ポリゴンの3頂点間で線形補間されます。
これにより、フラグメントシェーダーは頂点に対する自身の位置を知ったり、サンプリングすべきテクスチャのUV座標を取得したりできます。
つまり、3頂点でUV座標を指定すれば、ポリゴンの真ん中のフラグメントであっても線形補間された真ん中のUV座標を取得できるわけです。
